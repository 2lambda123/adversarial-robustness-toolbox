{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8093e27a-33f6-4cd9-a47b-ea94c3d0c514",
   "metadata": {},
   "source": [
    "# Huggingface with ART\n",
    "\n",
    "In this notebook we will go over how to use the Huggingface AIP with ART. This can enable us to train robust foundation models which act over images. \n",
    "\n",
    "Currently this is a developing feature, and so not all ART tools are supported. Further tools and development is planned. As of ART 1.16 we support: \n",
    "+ Using a Pytorch backend.\n",
    "+ Evasion attacks and defences on classical classification tasks such as image classification, but not tasks such as object detection.\n",
    "\n",
    "If you have a use case that is not supported (or find a bug in this new feature!) please raise an issiue on ART.\n",
    "\n",
    "Let's look at how we can use ART to secure Huggingface models!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549129e5-f6f4-4995-b334-d22cb4cae76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports for the notebook\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from art.estimators.hugging_face import HuggingFaceClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adf2bba-efc1-4db7-8041-698105537b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use CIFAR data for the notebook.\n",
    "def get_cifar_data():\n",
    "    \"\"\"\n",
    "    Get CIFAR-10 data.\n",
    "    :return: cifar train/test data.\n",
    "    \"\"\"\n",
    "    train_set = datasets.CIFAR10('./data', train=True, download=True)\n",
    "    test_set = datasets.CIFAR10('./data', train=False, download=True)\n",
    "\n",
    "    x_train = train_set.data.astype(np.float32)\n",
    "    y_train = np.asarray(train_set.targets)\n",
    "\n",
    "    x_test = test_set.data.astype(np.float32)\n",
    "    y_test = np.asarray(test_set.targets)\n",
    "\n",
    "    x_train = np.moveaxis(x_train, [3], [1])\n",
    "    x_test = np.moveaxis(x_test, [3], [1])\n",
    "\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f797586-480b-432e-8b55-26a4ac2360f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_model(architecture='google/vit-base-patch16-224'):\n",
    "    \"\"\"\n",
    "    Train a cifar classifier\n",
    "    \"\"\"\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = get_cifar_data()\n",
    "\n",
    "    # Here we load a Huggingface model using the transformers library.\n",
    "    model = transformers.AutoModelForImageClassification.from_pretrained(architecture,\n",
    "                                                                         ignore_mismatched_sizes=True,\n",
    "                                                                         num_labels=10)\n",
    "\n",
    "    # The HuggingFaceClassifier follows broadly the same API as the PyTorchClassifier\n",
    "    # So we can supply the loss function, the input shape of the data we will supply, the optimizer, etc.\n",
    "    # Note, frequently we will be performing fine-tuning or transfer learning with vision transformners and \n",
    "    # so we may be fine-tuning on differently sized inputs. \n",
    "    # The input_shape argument refers to the shape of the supplied input data which may be different to \n",
    "    # the shape required by the model. \n",
    "    # To handle this HuggingFaceClassifier has an extra argument of processor which will act on \n",
    "    # every batch to process the data into the correct form required by the supplied model.\n",
    "    # This needs to be manually specified by the user. For many attacks and defences to work it needs to be a \n",
    "    # differentiable funciton. \n",
    "    # Here the processor is a simple upsampler to enlarge the cifar images into the right size.\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "    upsampler = torch.nn.Upsample(scale_factor=7, mode='nearest')\n",
    "\n",
    "    hf_model = HuggingFaceClassifier(model, \n",
    "                                    loss=torch.nn.CrossEntropyLoss(),\n",
    "                                    optimizer=optimizer,\n",
    "                                    input_shape=(3, 32, 32),\n",
    "                                    nb_classes=10,\n",
    "                                    processor=upsampler)\n",
    "\n",
    "    hf_model.fit(x_train, y_train, nb_epochs=2, display_progress_bar=True)\n",
    "    return hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f68d34-e777-48b4-bdca-7c52a63e6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_base_model = train_base_model()\n",
    "torch.save(hf_base_model.model.state_dict(), 'hf_base_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a370096-d145-42cf-a59e-c553d81b0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pgd(architecture, model_to_test='hf_base_model.pt'):\n",
    "    \"\"\"\n",
    "    Here we can test the model we trained against a PGD attack.\n",
    "    \"\"\"\n",
    "    \n",
    "    import os\n",
    "    from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "    (x_train, y_train), (x_test, y_test) = get_cifar_data()\n",
    "    model = transformers.AutoModelForImageClassification.from_pretrained(architecture,\n",
    "                                                                         ignore_mismatched_sizes=True,\n",
    "                                                                         num_labels=10)\n",
    "    \n",
    "    # Load the model state dict from the training loop we just performed.\n",
    "    model.load_state_dict(torch.load(os.path.join('..', model_to_test)))\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Set it up as a HuggingFaceClassifier\n",
    "    hf_model = HuggingFaceClassifier(model, \n",
    "                                    loss=torch.nn.CrossEntropyLoss(),\n",
    "                                    optimizer=optimizer,\n",
    "                                    input_shape=(3, 32, 32),\n",
    "                                    nb_classes=10,\n",
    "                                    processor=torch.nn.Upsample(scale_factor=7, mode='nearest'))\n",
    "\n",
    "    # Let's just use 10 samples for quick demo purposes\n",
    "    num_samples = 10\n",
    "    outputs = hf_model(x_test[:num_samples])\n",
    "    acc = np.sum(np.argmax(outputs.cpu().detach().numpy(), axis=1) == y_test[:num_samples]) / len(y_test[:num_samples])\n",
    "    print('clean acc ', acc)\n",
    "\n",
    "    # The backend of the HuggingFaceClassifier is the existing PyTorchClassifier. Thus we can interface HuggingFaceClassifier with\n",
    "    # aleadry existing attacks in ART which support pytorch. Here we use ProjectedGradientDescentPyTorch.\n",
    "    attacker = ProjectedGradientDescentPyTorch(hf_model, eps=8/255, eps_step=1/255)\n",
    "    x_test_adv_robust = attacker.generate(x_test[:num_samples])\n",
    "    outputs = hf_model(x_test_adv_robust)\n",
    "    acc = np.sum(np.argmax(outputs.cpu().detach().numpy(), axis=1) == y_test[:num_samples]) / len(y_test[:num_samples])\n",
    "    print('adv acc ', acc)\n",
    "\n",
    "    # We can display the adversarial examples to highlight the added perturbation to the original sample.\n",
    "    x_test_adv_robust = np.moveaxis(x_test_adv_robust, [1], [3])\n",
    "    x_test = np.moveaxis(x_test, [1], [3])\n",
    "\n",
    "    delta = x_test[:num_samples] - x_test_adv_robust\n",
    "\n",
    "    delta = (delta - np.min(delta)) / (np.max(delta) - np.min(delta))\n",
    "    fig, axs = plt.subplots(3, 3)\n",
    "    for i in range(3):\n",
    "        axs[i, 0].imshow(x_test_adv_robust[i])\n",
    "        axs[i, 1].imshow(x_test[i])\n",
    "        axs[i, 2].imshow(delta[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4625ff-103f-49d2-90f9-503f1ea43e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pgd(architecture='google/vit-base-patch16-224', model_to_test='hf_base_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81f918-e716-457d-a665-835542cf5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that we can attack the Huggingface transformer, so now let's use one of the defences in ART!\n",
    "\n",
    "def adversarial_train():\n",
    "    from art.defences.trainer import AdversarialTrainerMadryPGD\n",
    "    (x_train, y_train), (x_test, y_test) = get_cifar_data()\n",
    "    model = transformers.AutoModelForImageClassification.from_pretrained('google/vit-base-patch16-224',\n",
    "                                                                         ignore_mismatched_sizes=True,\n",
    "                                                                         num_labels=10)\n",
    "\n",
    "    upsampler = torch.nn.Upsample(scale_factor=7, mode='nearest')\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    hf_model = HuggingFaceClassifier(model, \n",
    "                                    loss=torch.nn.CrossEntropyLoss(), \n",
    "                                    input_shape=(3, 32, 32),\n",
    "                                    nb_classes=10,\n",
    "                                    optimizer=optimizer, \n",
    "                                    processor=upsampler)\n",
    "\n",
    "    # We can now use adversarial training with Madry's protocol.\n",
    "    trainer = AdversarialTrainerMadryPGD(hf_model,\n",
    "                                         nb_epochs=10,\n",
    "                                         eps=8/255,\n",
    "                                         eps_step=1/255,\n",
    "                                         max_iter=10)\n",
    "\n",
    "    trainer.fit(x_train, y_train, display_progress_bar=True)\n",
    "    torch.save(trainer._classifier.model.state_dict(), 'hf_adv_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76373745-f886-4f1f-9452-ec648753b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below to run the adverarial training, it can take some time depending on available hardware. \n",
    "# The expected runtime is around 15 hours using a Nvidia V100 GPU.\n",
    "\n",
    "adversarial_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c859e2-c18a-4598-999b-b7621772a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now test the adversariallty trained model and we can see we have done from 0% robustness to XXX%.\n",
    "test_pgd(architecture='google/vit-base-patch16-224', model_to_test='hf_adv_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeead39-4b74-4b60-bd4b-a933fb7eebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also try with different models, for example here we try the functions with a different architecture\n",
    "\n",
    "hf_base_model = train_base_model(architecture='microsoft/swin-tiny-patch4-window7-224')\n",
    "torch.save(hf_base_model.model.state_dict(), 'swin_tiny_base_model.pt')\n",
    "\n",
    "test_pgd(architecture='microsoft/swin-tiny-patch4-window7-224', model_to_test='swin_tiny_base_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ccae2-4f26-402f-be21-bc3003f5a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also try different architectures, for example one of the most popular models on Huggingface is the resn\n",
    "def train_using_timm_model():\n",
    "    import timm\n",
    "    \n",
    "    model = timm.create_model('resnet50.a1_in1k', pretrained=True)\n",
    "    upsampler = torch.nn.Upsample(scale_factor=7, mode='nearest')\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    hf_model = HuggingFaceClassifier(model, \n",
    "                                    loss=torch.nn.CrossEntropyLoss(), \n",
    "                                    input_shape=(3, 32, 32),\n",
    "                                    nb_classes=10,\n",
    "                                    optimizer=optimizer, \n",
    "                                    processor=upsampler)\n",
    "    (x_train, y_train), (x_test, y_test) = get_cifar_data()\n",
    "    hf_model.fit(x_train, y_train, nb_epochs=2, display_progress_bar=True)\n",
    "\n",
    "    return hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584e1db-bc18-453d-9c8b-a313d1c9267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = train_using_timm_model()\n",
    "torch.save(hf_base_model.model.state_dict(), 'timm_resnet_50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3de85-965a-45fe-9870-7858e6527d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_train_timm():\n",
    "    from art.defences.trainer import AdversarialTrainerMadryPGD\n",
    "    import timm\n",
    "    (x_train, y_train), (x_test, y_test) = get_cifar_data()\n",
    "\n",
    "    model = timm.create_model('resnet50.a1_in1k', pretrained=True)\n",
    "\n",
    "    upsampler = torch.nn.Upsample(scale_factor=7, mode='nearest')\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    hf_model = HuggingFaceClassifier(model, \n",
    "                                    loss=torch.nn.CrossEntropyLoss(), \n",
    "                                    input_shape=(3, 32, 32),\n",
    "                                    nb_classes=10,\n",
    "                                    optimizer=optimizer, \n",
    "                                    processor=upsampler)\n",
    "\n",
    "    # We can now use adversarial training with Madry's protocol.\n",
    "    trainer = AdversarialTrainerMadryPGD(hf_model,\n",
    "                                         nb_epochs=10,\n",
    "                                         eps=8/255,\n",
    "                                         eps_step=1/255,\n",
    "                                         max_iter=10)\n",
    "\n",
    "    trainer.fit(x_train, y_train, display_progress_bar=True)\n",
    "    torch.save(trainer._classifier.model.state_dict(), 'timm_resnet_50_adv_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ba410-7352-494b-8029-c747e5378855",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_train_timm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29b5ab-7f5b-4136-903e-fc0442c4f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from transformers.modeling_outputs import ImageClassifierOutput\n",
    "from art.estimators.hugging_face import HuggingFaceClassifier\n",
    "\n",
    "class ModelConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "            self,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Model(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    Create model for pytorch.\n",
    "\n",
    "    The weights and biases are identical to the TensorFlow model in get_classifier_tf().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=7)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(4, 4)\n",
    "        self.fullyconnected = torch.nn.Linear(25, 10)\n",
    "\n",
    "    # pylint: disable=W0221\n",
    "    # disable pylint because of API requirements for function\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward function to evaluate the model\n",
    "        :param x: Input to the model\n",
    "        :return: Prediction of the model\n",
    "        \"\"\"\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(-1, 25)\n",
    "        x = self.fullyconnected(x)\n",
    "        return ImageClassifierOutput(logits=x)\n",
    "\n",
    "config = ModelConfig()\n",
    "pt_model = Model(config=config)\n",
    "optimizer = torch.optim.Adam(pt_model.parameters(), lr=0.01)\n",
    "\n",
    "hf_classifier = HuggingFaceClassifier(pt_model,\n",
    "                                      loss=torch.nn.CrossEntropyLoss(),\n",
    "                                      optimizer=optimizer,\n",
    "                                      input_shape=(1, 28, 28),\n",
    "                                      nb_classes=10,\n",
    "                                      clip_values=(0, 1),\n",
    "                                      processor=None)\n",
    "\n",
    "return hf_classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
